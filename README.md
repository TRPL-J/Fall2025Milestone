# Fall 2025 Milestone: Temporal Point Process Evaluation

Baseline evaluation and analysis of Temporal Point Process (TPP) models on stationary and non-stationary data.

## ğŸ“‹ Overview

This project evaluates seven baseline TPP models from the EasyTPP framework plus Meta-TPP across:
- 5 real-world datasets (Amazon, Retweet, Taxi, Taobao, StackOverflow)
- Synthetic stationary multivariate Hawkes processes
- Synthetic non-stationary Hawkes processes (regime concatenation)

**Key Findings:**
- Most models show 17-20 percentage point degradation in type prediction under non-stationarity
- AttNHP, THP, SAHP show severe degradation (+13.9 to +20.2pp error increase)
- FullyNN and Meta-TPP demonstrate robustness to regime changes
- Three novel architectural ideas proposed to address non-stationary dynamics

---

## ğŸ–¥ï¸ Hardware Requirements

All experiments were conducted on **Google Colab** with the following configuration:

| Component | Specification |
|-----------|--------------|
| **GPU** | NVIDIA A100 (80GB) |
| **Runtime Type** | A100 GPU with High RAM |
| **Environment** | Google Colab Python 3.x with CUDA |

### Setting Up Google Colab Runtime

1. Open your notebook in Google Colab
2. Navigate to `Runtime` â†’ `Change runtime type`
3. Configure settings:
   - **Hardware accelerator**: `GPU`
   - **GPU type**: `A100`
   - **Runtime shape**: `High-RAM`
4. Click `Save`

---

## ğŸ“ Google Drive Setup

### Required Directory Structure

Before running any notebooks, create the following directory structure in your Google Drive:

```bash
/content/drive/MyDrive/Colab Notebooks/MilestoneFall2025/
â”œâ”€â”€ Datasets/           # Downloaded and generated datasets
â”œâ”€â”€ checkpoints/        # Model checkpoints during training
â”œâ”€â”€ configs/            # Configuration files
â””â”€â”€ results/            # Output results and tables
```

### Creating Directories

You can create these directories manually in Google Drive, or run this code block in any Colab notebook:

```python
import os

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Base directory
base_dir = '/content/drive/MyDrive/Colab Notebooks/MilestoneFall2025'

# Create directory structure
directories = ['Datasets', 'checkpoints', 'configs', 'results']
for dir_name in directories:
    os.makedirs(os.path.join(base_dir, dir_name), exist_ok=True)

print("âœ“ Directory structure created successfully!")
```

---

## ğŸ“Š Dataset Preparation

### Real-World Datasets

**Download the five real-world datasets from:**

ğŸ”— **Google Drive**: https://drive.google.com/drive/u/0/folders/1f8k82-NL6KFKuNMsUwozmbzDSFycYvz7

The datasets include:
- **Amazon**: User product review events (16 categories, 5,200 users)
- **Retweet**: User retweet sequences (3 types, 5,200 users)
- **Taxi**: NYC taxi pick-up/drop-off events (10 types, 2,000 drivers)
- **Taobao**: Shopping click behaviors (20 categories, 4,800 users)
- **StackOverflow**: Badge award sequences (22 types, 2,200 users)

### Expected Dataset Structure

Place all downloaded datasets in the `Datasets/` directory with this structure:

```bash
Datasets/
â”œâ”€â”€ amazon/
â”‚   â”œâ”€â”€ train.pkl
â”‚   â”œâ”€â”€ dev.pkl
â”‚   â””â”€â”€ test.pkl
â”œâ”€â”€ retweet/
â”‚   â”œâ”€â”€ train.pkl
â”‚   â”œâ”€â”€ dev.pkl
â”‚   â””â”€â”€ test.pkl
â”œâ”€â”€ taxi/
â”‚   â”œâ”€â”€ train.pkl
â”‚   â”œâ”€â”€ dev.pkl
â”‚   â””â”€â”€ test.pkl
â”œâ”€â”€ taobao/
â”‚   â”œâ”€â”€ train.pkl
â”‚   â”œâ”€â”€ dev.pkl
â”‚   â””â”€â”€ test.pkl
â””â”€â”€ stackoverflow/
    â”œâ”€â”€ train.pkl
    â”œâ”€â”€ dev.pkl
    â””â”€â”€ test.pkl
```

### Synthetic Datasets

**No manual download required!** The following datasets are automatically generated by the notebooks:

- **Stationary Hawkes** (Task 2): Generated by `Task2.ipynb`
- **Non-Stationary Hawkes** (Task 4): Generated by `Task4.ipynb`

---

## ğŸš€ Notebook Execution Order

Execute the notebooks in the following sequence to reproduce all results:

### 1ï¸âƒ£ Task1_Final.ipynb
**Purpose**: Baseline Models on Real-World Datasets

**What it does:**
- Evaluates 7 baseline TPP models on 5 real-world datasets
- Models: RMTPP, NHP, FullyNN, SAHP, THP, IntensityFree, AttNHP
- Generates consolidated results table

**Output:**
```
results/Task1/Task1_consolidated_results.csv
```

**Report Section**: Task 1 (Table 1.2)

---

### 2ï¸âƒ£ Task2.ipynb
**Purpose**: Stationary Hawkes Data Generation

**What it does:**
- Generates 500 stationary multivariate Hawkes sequences
- Uses Sparklen library with bivariate Hawkes process
- Converts to EasyTPP format (d=2, T=20, exponential kernel)

**Output:**
```
Datasets/stationary_hawkes/train.pkl (300 sequences)
Datasets/stationary_hawkes/dev.pkl   (100 sequences)
Datasets/stationary_hawkes/test.pkl  (100 sequences)
```

**Report Section**: Task 2

---

### 3ï¸âƒ£ Task4.ipynb
**Purpose**: Non-Stationary Hawkes Data Generation

**What it does:**
- Generates 500 non-stationary Hawkes sequences
- Three-regime concatenation (Regime 1: baseline, Regime 2: high activity, Regime 3: bursty)
- Creates piecewise-stationary sequences with global non-stationarity

**Output:**
```
Datasets/nonstationary_hawkes/train.pkl (300 sequences)
Datasets/nonstationary_hawkes/dev.pkl   (100 sequences)
Datasets/nonstationary_hawkes/test.pkl  (100 sequences)
```

**Report Section**: Task 4

---

### 4ï¸âƒ£ Task3_Final.ipynb
**Purpose**: Evaluation on Stationary Hawkes

**What it does:**
- Evaluates 7 baselines + Meta-TPP on stationary Hawkes data
- Controlled benchmark with known generative dynamics
- Generates performance table

**Output:**
```
results/Task3/Task3_report_table.csv
```

**Report Section**: Task 3 (Table 3.1)

---

### 5ï¸âƒ£ Task5_Final.ipynb
**Purpose**: Evaluation on Non-Stationary Hawkes + Degradation Analysis

**What it does:**
- Evaluates 8 models on non-stationary Hawkes data
- Computes degradation metrics (stationary vs non-stationary)
- Identifies most robust models and failure modes

**Output:**
```
results/Task5/Task5_report_table.csv
results/Task5/degradation_analysis.csv
```

**Report Section**: Task 5 (Tables 5.1 and 5.2)

---

## ğŸ“¦ Expected Outputs

Upon successful completion of all notebooks, you will have:

### Result Files
| File | Content | Report Reference |
|------|---------|------------------|
| `results/Task1/Task1_consolidated_results.csv` | Real-world dataset performance | Table 1.2 |
| `results/Task3/Task3_report_table.csv` | Stationary Hawkes performance | Table 3.1 |
| `results/Task5/Task5_report_table.csv` | Non-stationary Hawkes performance | Table 5.1 |
| `results/Task5/degradation_analysis.csv` | Degradation analysis | Table 5.2 |

### Generated Datasets
| Dataset | Sequences | Description |
|---------|-----------|-------------|
| Stationary Hawkes | 500 (300/100/100) | Bivariate, T=20, exponential kernel |
| Non-Stationary Hawkes | 500 (300/100/100) | Three-regime concatenation |

### Model Checkpoints
All trained models are automatically saved to:
```
checkpoints/<task_name>/<model_name>/
```

Checkpoints can be reused for evaluation without retraining.

---

## ğŸ”§ Technical Details

### Package Installation

**No manual installation required!** Each notebook automatically installs all dependencies:

- EasyTPP (Temporal Point Process framework)
- Sparklen (Hawkes process simulation)
- PyTorch (Deep learning backend)
- NumPy, Pandas, Matplotlib (Data processing and visualization)

Dependencies are installed at the beginning of each notebook.

### Random Seeds

Notebooks use fixed random seeds for reproducibility:
- Synthetic data generation uses consistent seeds
- Model training may have slight variations due to GPU non-determinism

### Memory Management

Notebooks include optimization strategies to prevent OOM errors:
- GPU cache clearing after each model training
- Garbage collection between experiments
- Batch size optimization for A100 GPU

### Model Hyperparameters

All models use consistent hyperparameters across experiments:

| Model | Hidden Size | Layers | Attention Heads |
|-------|-------------|--------|-----------------|
| RMTPP | 32 | 2 | - |
| NHP | 64 | 2 | - |
| FullyNN | 32 | 2 | - |
| SAHP | 32 | 2 | 2 |
| THP | 64 | 2 | 2 |
| IntensityFree | 32 | 2 | - |
| AttNHP | 32 | 1 | 2 |

Training configuration:
- Optimizer: Adam (default parameters)
- Batch size: 256
- Early stopping: Log-likelihood on dev set
- Learning rate decay: None

---

## ğŸ“ˆ Key Results Summary

### Task 1: Real-World Datasets

**Best Models:**
- **Time Prediction (RMSE)**: IntensityFree (lowest on Amazon, Taobao, Taxi)
- **Type Prediction**: THP, IntensityFree (error rates 39-65%)

**Notable Findings:**
- AttNHP catastrophic failure on Amazon (RMSE: 8711.428, ~3000Ã— higher)
- Taxi dataset shows simplest dynamics (8-12% error rates)

### Task 3: Stationary Hawkes

**Best Models:**
- **Time Prediction**: AttNHP (RMSE: 0.897)
- **Type Prediction**: THP (52.5% error rate)

**Observations:**
- Consistent performance across models (52-58% error rates)
- Meta-TPP higher RMSE (2.090) but competitive type prediction

### Task 5: Non-Stationary Hawkes

**Most Robust Models:**
- **FullyNN**: -3.8pp error rate improvement (50.3%)
- **Meta-TPP**: -5.3pp error rate improvement (49.4%)

**Most Vulnerable Models:**
- **THP**: +20.2pp degradation (72.7% error rate)
- **RMTPP**: +18.3pp degradation (72.9% error rate)
- **NHP**: +17.6pp degradation (71.9% error rate)

**Critical Finding:**
> Attention-based models (THP, SAHP, AttNHP) show 13.9-20.2 percentage point degradation in type prediction under non-stationarity, representing a 33-38% relative increase in error rate.

---

## ğŸ¯ Proposed Solutions (Task 6)

Three complementary architectural ideas to improve robustness under non-stationarity:

### Idea 1: Adaptive History Attention with Regime-Gated Forgetting
**Addresses**: Stale history from previous regimes  
**Mechanism**: Change detection + attention decay based on regime distance  
**Target**: Type prediction degradation in attention-based models

### Idea 2: Regime-Adaptive Temporal Positional Encoding
**Addresses**: Regime-dependent time semantics  
**Mechanism**: Context-modulated frequency scaling of sinusoidal encodings  
**Target**: Time prediction stability across regimes

### Idea 3: Hierarchical Regime-Token Architecture
**Addresses**: Piecewise-stationary structure  
**Mechanism**: Two-level attention (local events + regime tokens)  
**Target**: Computational efficiency and interpretability

**Integration**: The three ideas work synergistically to handle history relevance, temporal representation, and structural organization.

---

## ğŸ“ Citation

If you use this code or methodology, please cite:

```bibtex
@techreport{milestone2025,
  title={Fall 2025 Milestone: Baseline Evaluation and Brainstorm for Temporal Point Processes},
  author={Josh Job Joseph},
  year={2025},
  institution={Baylor University}
}
```

---

## ğŸ“„ Report

The full technical report is available in:
- **LaTeX Source**: `milestone_report_final_submission.tex`
- **PDF**: `milestone_report_final_submission.pdf`

---

## ğŸ” Troubleshooting

### Common Issues

#### Issue: "Runtime disconnected"
**Solution**: A100 GPU sessions may timeout after inactivity. Reconnect and re-run from the last checkpoint.

#### Issue: "Out of memory (OOM)"
**Solution**: 
- Ensure you selected "High-RAM" runtime shape
- Restart runtime and clear GPU cache
- Reduce batch size if problem persists

#### Issue: "Dataset files not found"
**Solution**:
- Verify Google Drive is mounted: `drive.mount('/content/drive')`
- Check dataset paths match the directory structure
- Re-download datasets from the Google Drive link

#### Issue: "Module not found"
**Solution**:
- Re-run the installation cells at the beginning of the notebook
- Restart runtime if packages fail to install

---

## ğŸ“§ Contact

For questions or issues, please open an issue in the repository or contact josh_joseph3@baylor.edu

---

## ğŸ™ Acknowledgments

- **EasyTPP Framework**: https://github.com/ant-research/EasyTemporalPointProcess
- **Sparklen Library**: https://github.com/romain-e-lacoste/sparklen
- **Datasets**: Amazon, Retweet, Taxi, Taobao, StackOverflow (via EasyTPP repository)

---
